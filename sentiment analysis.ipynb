{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shagunsaboo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/shagunsaboo/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shagunsaboo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk import word_tokenize \n",
    "import io\n",
    "import os\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@SouthwestAir I am scheduled for the morning, 2 days after the fact, yes..not sure why my evening flight was the only one Cancelled Flightled'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data=pd.read_csv('/Users/shagunsaboo/Downloads/0000000000002747_training_twitter_x_y_train.csv')\n",
    "training_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@AmericanAir In car gng to DFW. Pulled over 1hr ago - very icy roads. On-hold with AA since 1hr. Can't reach arpt for AA2450. Wat 2 do?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data=pd.read_csv(\"/Users/shagunsaboo/Downloads/0000000000002747_test_twitter_x_test.csv\")\n",
    "testing_data[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=training_data[\"text\"]\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10980, 1), (10980, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest=testing_data[\"text\"]\n",
    "xtest=np.array(xtest)\n",
    "xtest=xtest.reshape(len(xtest),1)\n",
    "xtest.shape\n",
    "y=training_data['airline_sentiment']\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "x=x.reshape(len(x),1)\n",
    "y=y.reshape(len(y),1)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=np.append(x,y,axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=xtest\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'SouthwestAir',\n",
       "   'I',\n",
       "   'am',\n",
       "   'scheduled',\n",
       "   'for',\n",
       "   'the',\n",
       "   'morning',\n",
       "   ',',\n",
       "   '2',\n",
       "   'days',\n",
       "   'after',\n",
       "   'the',\n",
       "   'fact',\n",
       "   ',',\n",
       "   'yes..not',\n",
       "   'sure',\n",
       "   'why',\n",
       "   'my',\n",
       "   'evening',\n",
       "   'flight',\n",
       "   'was',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'Cancelled',\n",
       "   'Flightled'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "c=0\n",
    "for text,category in train:\n",
    "    c+=1\n",
    "    documents.append((word_tokenize(text), category))\n",
    "print(\"The End\")\n",
    "documents[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The End\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['[',\n",
       "  '``',\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'In',\n",
       "  'car',\n",
       "  'gng',\n",
       "  'to',\n",
       "  'DFW',\n",
       "  '.',\n",
       "  'Pulled',\n",
       "  'over',\n",
       "  '1hr',\n",
       "  'ago',\n",
       "  '-',\n",
       "  'very',\n",
       "  'icy',\n",
       "  'roads',\n",
       "  '.',\n",
       "  'On-hold',\n",
       "  'with',\n",
       "  'AA',\n",
       "  'since',\n",
       "  '1hr',\n",
       "  '.',\n",
       "  'Ca',\n",
       "  \"n't\",\n",
       "  'reach',\n",
       "  'arpt',\n",
       "  'for',\n",
       "  'AA2450',\n",
       "  '.',\n",
       "  'Wat',\n",
       "  '2',\n",
       "  'do',\n",
       "  '?',\n",
       "  \"''\",\n",
       "  ']'],\n",
       " ['[',\n",
       "  \"'\",\n",
       "  '@',\n",
       "  'AmericanAir',\n",
       "  'after',\n",
       "  'all',\n",
       "  ',',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'didn',\n",
       "  'â€™',\n",
       "  't',\n",
       "  'land',\n",
       "  'in',\n",
       "  'identical',\n",
       "  'or',\n",
       "  'worse',\n",
       "  ')',\n",
       "  'conditions',\n",
       "  'at',\n",
       "  'GRK',\n",
       "  'according',\n",
       "  'to',\n",
       "  'METARs',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  ']']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_documents = []\n",
    "c=0\n",
    "for text in test:\n",
    "    c+=1\n",
    "    test_documents.append(word_tokenize(str(text)))\n",
    "print(\"The End\")\n",
    "test_documents[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'AmericanAir',\n",
       "   'how',\n",
       "   'nice',\n",
       "   'it',\n",
       "   'would',\n",
       "   'be',\n",
       "   'if',\n",
       "   'you',\n",
       "   'had',\n",
       "   'helpful',\n",
       "   'flight',\n",
       "   'attendants',\n",
       "   'instead',\n",
       "   'of',\n",
       "   'the',\n",
       "   'rude',\n",
       "   'nasty',\n",
       "   'ones',\n",
       "   'you',\n",
       "   'employ',\n",
       "   '.',\n",
       "   '#',\n",
       "   'WhyAreYouYelling'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'vanessaannz',\n",
       "   'seriously',\n",
       "   ',',\n",
       "   'you',\n",
       "   'hate',\n",
       "   '@',\n",
       "   'AmericanAir',\n",
       "   'since',\n",
       "   'they',\n",
       "   'ca',\n",
       "   \"n't\",\n",
       "   'accommodate',\n",
       "   'you',\n",
       "   'due',\n",
       "   'to',\n",
       "   'inclemental',\n",
       "   'weather',\n",
       "   'disruptions',\n",
       "   '?',\n",
       "   'lol',\n",
       "   ',',\n",
       "   'very',\n",
       "   'funny'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(documents)\n",
    "documents[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('better', 'RBR')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "w = \"better\"\n",
    "pos_tag([w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "#stops, string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    #regex = re.compile('[a-zA-Z0-9_-]+$')\n",
    "    regex = re.compile('[a-zA-Z_-]+$')\n",
    "    for w in words:\n",
    "        if w.lower() not in stops and len(w)>2 and not w.isnumeric() and re.match(regex,w):\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(clean_review(document), category) for document, category in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = [clean_review(document) for document in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents = documents\n",
    "testing_documents = test_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [category for document, category in training_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Train Data\n",
    "\n",
    "text_documents = [\" \".join(document) for document, category in training_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining All features in each tuple for Test Data\n",
    "\n",
    "test_text_documents = [\" \".join(document) for document in testing_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count_vec = CountVectorizer(max_features = 2000, ngram_range=(1,2))\n",
    "count_vec = CountVectorizer(max_features = 7000)\n",
    "x_train_features = count_vec.fit_transform(text_documents)\n",
    "x_train_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 7000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='shagun'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile('[a-zA-Z_-]+$')\n",
    "re.match(regex,'shagun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__rwg__',\n",
       " '_austrian',\n",
       " '_defcon_',\n",
       " '_emmaclifford',\n",
       " '_exact_',\n",
       " '_justdippin_',\n",
       " 'a_life_story_',\n",
       " 'aa',\n",
       " 'aaaand',\n",
       " 'aadvantage',\n",
       " 'aafail',\n",
       " 'aal',\n",
       " 'aaron',\n",
       " 'aarp',\n",
       " 'abandon',\n",
       " 'abandonment',\n",
       " 'abassinet',\n",
       " 'abbreve',\n",
       " 'abc',\n",
       " 'abcnetwork',\n",
       " 'abcnews',\n",
       " 'abduct',\n",
       " 'abi',\n",
       " 'abigailedge',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'aboout',\n",
       " 'abounds',\n",
       " 'abq',\n",
       " 'abroad',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorber',\n",
       " 'absoulutely',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abysmal',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'acces',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accomidating',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accrue',\n",
       " 'acct',\n",
       " 'accts',\n",
       " 'accumulation',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accuratetraveltimes',\n",
       " 'accuse',\n",
       " 'achieve',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledgement',\n",
       " 'acknowledgment',\n",
       " 'acnewsguy',\n",
       " 'acosta',\n",
       " 'acoustic',\n",
       " 'acpt',\n",
       " 'acquire',\n",
       " 'across',\n",
       " 'act',\n",
       " 'actingoutmgmnt',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'active_aly',\n",
       " 'actively',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'acu',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adam',\n",
       " 'adam_karren',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addair',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additonal',\n",
       " 'addr',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'addtl',\n",
       " 'adjacent',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admiralsclub',\n",
       " 'admit',\n",
       " 'adolfo',\n",
       " 'adopt',\n",
       " 'adopting',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adv',\n",
       " 'advan',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'advertise',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advis',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'advsry',\n",
       " 'aerocivilcol',\n",
       " 'aerojobmarket',\n",
       " 'aeroport',\n",
       " 'aex',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affiliate',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afiliates',\n",
       " 'aflame',\n",
       " 'afraid',\n",
       " 'african',\n",
       " 'aft',\n",
       " 'afterall',\n",
       " 'afternoon',\n",
       " 'aftr',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggiemensgolf',\n",
       " 'aggravate',\n",
       " 'aggravation',\n",
       " 'aggressive',\n",
       " 'agnt',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreement',\n",
       " 'agt',\n",
       " 'agts',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahold',\n",
       " 'ahoy',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'airbusintheus',\n",
       " 'aircanada',\n",
       " 'aircargo',\n",
       " 'aircraft',\n",
       " 'aires',\n",
       " 'airfare',\n",
       " 'airfarewatchdog',\n",
       " 'airline',\n",
       " 'airlinegeeks',\n",
       " 'airlineguys',\n",
       " 'airlinequality',\n",
       " 'airliner',\n",
       " 'airlines',\n",
       " 'airlinesecurity',\n",
       " 'airnzusa',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airportcardio',\n",
       " 'airpt',\n",
       " 'airside',\n",
       " 'airstairs',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'ais',\n",
       " 'aisle',\n",
       " 'aka',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alamo',\n",
       " 'alan_bledsoe',\n",
       " 'alarm',\n",
       " 'alaska',\n",
       " 'alaskaair',\n",
       " 'alavera',\n",
       " 'alb',\n",
       " 'albany',\n",
       " 'albanyairport',\n",
       " 'albeit',\n",
       " 'albertbreer',\n",
       " 'album',\n",
       " 'albuquer',\n",
       " 'albuquerque',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alfamilyoffour',\n",
       " 'ali',\n",
       " 'alicia',\n",
       " 'align',\n",
       " 'alison',\n",
       " 'alist',\n",
       " 'alittlebetter',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allan',\n",
       " 'allegiantair',\n",
       " 'allegianttravel',\n",
       " 'allende',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'allgood',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'allowabl',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allready',\n",
       " 'allyoucanjetpass',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alreadyrebookedonce',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'also',\n",
       " 'alsonodrinkcartcomingaround',\n",
       " 'alstdi',\n",
       " 'alt',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altonbrownlive',\n",
       " 'always',\n",
       " 'alwaysdelayed',\n",
       " 'alwayshappensthere',\n",
       " 'alwayslate',\n",
       " 'alynewton',\n",
       " 'am',\n",
       " 'amagrino',\n",
       " 'amarillo',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazings',\n",
       " 'amazon',\n",
       " 'ambivalence',\n",
       " 'amen',\n",
       " 'amenity',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairbr',\n",
       " 'americanairlines',\n",
       " 'americanairlnes',\n",
       " 'americanairsucks',\n",
       " 'americanforlife',\n",
       " 'americanone',\n",
       " 'americant',\n",
       " 'americanview',\n",
       " 'amex',\n",
       " 'amin_aur',\n",
       " 'amirite',\n",
       " 'amm',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ams',\n",
       " 'amsterdam',\n",
       " 'amt',\n",
       " 'amy',\n",
       " 'amybruni',\n",
       " 'amypoehler',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'analystdoc',\n",
       " 'analysts',\n",
       " 'analytics',\n",
       " 'anamarketers',\n",
       " 'anaphylaxis',\n",
       " 'anarchy',\n",
       " 'anchorage',\n",
       " 'andchexmix',\n",
       " 'anderson',\n",
       " 'andrew',\n",
       " 'andrew_wasila',\n",
       " 'andrewbiga',\n",
       " 'andrewfallis',\n",
       " 'andrews',\n",
       " 'android',\n",
       " 'andthewinneris',\n",
       " 'andyellwood',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'angriest',\n",
       " 'angry',\n",
       " 'angryandsober',\n",
       " 'angrybird',\n",
       " 'angrycustomer',\n",
       " 'angrytraveler',\n",
       " 'angst',\n",
       " 'anhour',\n",
       " 'animal',\n",
       " 'anku',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annebevi',\n",
       " 'annettenaif',\n",
       " 'anni',\n",
       " 'anniversary',\n",
       " 'annnndddd',\n",
       " 'annnnddddd',\n",
       " 'annnnnd',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annricord',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answerphone',\n",
       " 'answerthephone',\n",
       " 'answerthis',\n",
       " 'ant_kneee',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipation',\n",
       " 'antigua',\n",
       " 'antitrust',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhelp',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyonethere',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apathetic',\n",
       " 'apathy',\n",
       " 'apeared',\n",
       " 'apnea',\n",
       " 'apollochplayers',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'apostrophe',\n",
       " 'apostrophefail',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'applaud',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'applepay',\n",
       " 'appleton',\n",
       " 'applicable',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'appoint',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'apx',\n",
       " 'aquadilla',\n",
       " 'arab',\n",
       " 'arbitrarily',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'ardent',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'areyounew',\n",
       " 'argentina',\n",
       " 'argg',\n",
       " 'argh',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'arkansas',\n",
       " 'arm',\n",
       " 'arminrosen',\n",
       " 'armrest',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arose',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'art',\n",
       " 'article',\n",
       " 'artisanal',\n",
       " 'aruba',\n",
       " 'aruba_airport',\n",
       " 'aruna',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ase',\n",
       " 'ash',\n",
       " 'asha',\n",
       " 'ashamed',\n",
       " 'ashley',\n",
       " 'ashleykatherton',\n",
       " 'asia',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askpaypal',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspen',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'assult',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'astound',\n",
       " 'astounds',\n",
       " 'at',\n",
       " 'atc',\n",
       " 'atct',\n",
       " 'ath',\n",
       " 'athlete',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attain',\n",
       " 'attdt',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attendants',\n",
       " 'attendee',\n",
       " 'attendents',\n",
       " 'attention',\n",
       " 'attentiveness',\n",
       " 'attitude',\n",
       " 'attitudeissues',\n",
       " 'attndt',\n",
       " 'atwonline',\n",
       " 'auciello',\n",
       " 'auckland',\n",
       " 'auction',\n",
       " 'audience',\n",
       " 'audition',\n",
       " 'auditorium',\n",
       " 'auf',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auh',\n",
       " 'aunt',\n",
       " 'aunty',\n",
       " 'aus',\n",
       " 'austic',\n",
       " 'austin',\n",
       " 'austinairport',\n",
       " 'australia',\n",
       " 'austrian',\n",
       " 'author',\n",
       " 'authoritative',\n",
       " 'authority',\n",
       " 'authorize',\n",
       " 'auto',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'automobile',\n",
       " 'autoresponse',\n",
       " 'av_duffy',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avatar',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avert',\n",
       " 'avgeek',\n",
       " 'aviation',\n",
       " 'avios',\n",
       " 'avis',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avon',\n",
       " 'avp',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'aweful',\n",
       " 'awesome',\n",
       " 'awesomeee',\n",
       " 'awesomeness',\n",
       " 'awful',\n",
       " 'awfulness',\n",
       " 'awheelchair',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awrd',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'awwweesssooomee',\n",
       " 'ayyy',\n",
       " 'ba_usa',\n",
       " 'baby',\n",
       " 'bach',\n",
       " 'bachelorpartymishap',\n",
       " 'back',\n",
       " 'backing',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backroads',\n",
       " 'backup',\n",
       " 'backwards',\n",
       " 'bad',\n",
       " 'badbadbad',\n",
       " 'badbusiness',\n",
       " 'badbussiness',\n",
       " 'badcustomerservice',\n",
       " 'badcustomersrvice',\n",
       " 'bademployeeproblem',\n",
       " 'badge',\n",
       " 'badges',\n",
       " 'badly',\n",
       " 'badmgmt',\n",
       " 'badpolicy',\n",
       " 'badservice',\n",
       " 'badwebsite',\n",
       " 'bae',\n",
       " 'baejet',\n",
       " 'bafore',\n",
       " 'baftz',\n",
       " 'bag',\n",
       " 'bagage',\n",
       " 'bagawim',\n",
       " 'baggage',\n",
       " 'baggagelost',\n",
       " 'bags',\n",
       " 'bahamas',\n",
       " 'bail',\n",
       " 'bailey',\n",
       " 'bait',\n",
       " 'baitandswitch',\n",
       " 'bake',\n",
       " 'baking',\n",
       " 'balance',\n",
       " 'baldordash',\n",
       " 'baldwin',\n",
       " 'ball',\n",
       " 'ballin',\n",
       " 'balls',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'bandie',\n",
       " 'bandwidth',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bankruptcy',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barbara',\n",
       " 'barclay',\n",
       " 'barclaycardus',\n",
       " 'barclays',\n",
       " 'barcodes',\n",
       " 'barely',\n",
       " 'barking',\n",
       " 'barklays',\n",
       " 'barnum',\n",
       " 'barrel',\n",
       " 'barrettkarabis',\n",
       " 'barrier',\n",
       " 'bars',\n",
       " 'barzegar',\n",
       " 'base',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bastard',\n",
       " 'bathroom',\n",
       " 'batman',\n",
       " 'battery',\n",
       " 'battierccipuppy',\n",
       " 'batting',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bbb_media',\n",
       " 'bbbne_sd_ks_ia',\n",
       " 'bcn',\n",
       " 'bcuz',\n",
       " 'bday',\n",
       " 'bdindallas',\n",
       " 'bdl',\n",
       " 'bdng',\n",
       " 'bdsm',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beamske',\n",
       " 'bean',\n",
       " 'beanie',\n",
       " 'beantownmatty',\n",
       " 'bear',\n",
       " 'bearable',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beatriz',\n",
       " 'beats',\n",
       " 'beatsmusic',\n",
       " 'beatstheothers',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'bed',\n",
       " 'bedofroses',\n",
       " 'beefjerky',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'befor',\n",
       " 'beg',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'begrudgingly',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'beingsuckontarmacsucks',\n",
       " 'belabor',\n",
       " 'belfast',\n",
       " 'belfastairport',\n",
       " 'belief',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'belize',\n",
       " 'bellagio',\n",
       " 'belligerent',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'ben',\n",
       " 'benadryl',\n",
       " 'bench',\n",
       " 'bene',\n",
       " 'beneficial',\n",
       " 'benefit',\n",
       " 'benjaminokeefe',\n",
       " 'bensonhenderson',\n",
       " 'beought',\n",
       " 'bereavement',\n",
       " 'bergstrom',\n",
       " 'berlin',\n",
       " 'bernhardtjh',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestairline',\n",
       " 'bestairlineever',\n",
       " 'bestemployees',\n",
       " 'bestflightever',\n",
       " 'besty',\n",
       " 'bet',\n",
       " 'betsy',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bff',\n",
       " 'bgm',\n",
       " 'bgr',\n",
       " 'bhm',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'biggie',\n",
       " 'bike',\n",
       " 'bila',\n",
       " 'bill',\n",
       " 'billing',\n",
       " 'billion',\n",
       " 'billmelate',\n",
       " 'bin',\n",
       " 'bingo',\n",
       " 'bins',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birder',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'birthdate',\n",
       " 'birthday',\n",
       " 'biscuit',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchy',\n",
       " 'bite',\n",
       " 'bitty',\n",
       " 'biz',\n",
       " 'bizarre',\n",
       " 'biztravel',\n",
       " 'bked',\n",
       " 'bkk',\n",
       " 'black',\n",
       " 'blackhistorymonth',\n",
       " 'blacklist',\n",
       " 'blacklivesmatter',\n",
       " 'blackmailed',\n",
       " 'blade',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blameshiftoverload',\n",
       " 'blanc',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blasting',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'blatimore',\n",
       " 'blegh',\n",
       " 'bleh',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindside',\n",
       " 'bliss',\n",
       " 'blizzard',\n",
       " 'bloat',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'blood',\n",
       " 'bloody',\n",
       " 'bloodymary',\n",
       " 'bloombergradio',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluecarpet',\n",
       " 'bluemanity',\n",
       " 'bluetiful',\n",
       " 'blushing',\n",
       " 'bmi',\n",
       " 'bna',\n",
       " 'bnasnow',\n",
       " 'bng',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'boat',\n",
       " 'bobbi',\n",
       " 'bobwesson',\n",
       " 'body',\n",
       " 'boeing',\n",
       " 'boeingairplanes',\n",
       " 'bogota',\n",
       " 'bohol',\n",
       " 'boil',\n",
       " 'boise',\n",
       " 'bold',\n",
       " 'boldflavors',\n",
       " 'bom',\n",
       " 'bonnie',\n",
       " 'bonsinthesky',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boofin',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'booklet',\n",
       " 'bookofnegroes',\n",
       " 'bool',\n",
       " 'boom',\n",
       " 'boooo',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'bora',\n",
       " 'border',\n",
       " 'borderline',\n",
       " 'bored',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bostonlogan',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bougth',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bqn',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brandloveaffair',\n",
       " 'brandmance',\n",
       " 'brandssayingbae',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'bretharold',\n",
       " 'brian',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'british_airways',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brokenpromises',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'bruh',\n",
       " 'brushing',\n",
       " 'brutal',\n",
       " 'btr',\n",
       " 'bttr',\n",
       " 'btv',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buenos',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumper',\n",
       " 'bumping',\n",
       " 'bunch',\n",
       " 'burbank',\n",
       " 'burning',\n",
       " 'burningman',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busiest',\n",
       " 'business',\n",
       " 'businessfirst',\n",
       " 'bussey',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butnot',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buying',\n",
       " 'buzz',\n",
       " 'bwahahaha',\n",
       " 'bwi',\n",
       " 'bwi_airport',\n",
       " 'bwood',\n",
       " 'bye',\n",
       " 'byebyejetblue',\n",
       " 'byod',\n",
       " 'bze',\n",
       " 'c_istudios',\n",
       " 'cab',\n",
       " 'cabcelled',\n",
       " 'cabin',\n",
       " 'cabine',\n",
       " 'cable',\n",
       " 'cabo',\n",
       " 'cac',\n",
       " 'cache',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x7000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 31492 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_features = count_vec.transform(test_text_documents)\n",
    "x_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=x_train_features\n",
    "ytrain=categories\n",
    "xtest=x_test_features\n",
    "ytest=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=0.2,kernel='linear')\n",
    "svc.fit(xtrain, ytrain)\n",
    "#svc.score(xtest, ytest)\n",
    "predict=svc.predict(xtest)\n",
    "prediction=np.array(predict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10980, 3660]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-947d05f0ceb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \"\"\"\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10980, 3660]"
     ]
    }
   ],
   "source": [
    "#svc.score(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p=pd.DataFrame(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.to_csv('result.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'neutral', 'positive',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MULTINOMIAL NAIVE BAYES SCORE TEST\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=0.83)\n",
    "clf.fit(xtrain.toarray(), ytrain)\n",
    "\n",
    "mnb=clf.predict(xtest)\n",
    "mnb=np.array(mnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
